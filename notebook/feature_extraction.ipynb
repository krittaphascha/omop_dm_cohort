{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krittaphas.chi\\AppData\\Local\\Temp\\ipykernel_13428\\2618961862.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlalchemy as sal\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "# Create a connection to the database\n",
    "server_database = os.getenv(\"SERVER_DATABASE\")\n",
    "engine = sal.create_engine(f'mssql+pyodbc://@{server_database}?trusted_connection=yes&driver=SQL+Server')\n",
    "conn = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get patients data\n",
    "pt = pd.read_csv('../data/cohort_28feb24.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 167838\n",
      "Total number of pt.: 167838\n"
     ]
    }
   ],
   "source": [
    "pt_df = pt[['person_id','first_date','year_of_birth']]\n",
    "\n",
    "print(\"Total rows:\" , len(pt_df))\n",
    "print(\"Total number of pt.:\", len(pt_df['person_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167838\n"
     ]
    }
   ],
   "source": [
    "pt_list = list(pt_df['person_id'].unique())\n",
    "print(len(pt_list))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting batch  1  of  17 subject  0  to  9999\n",
      "no exisiting dataframe, creating new one\n",
      "finising batch  1  of  17 number of records 283254\n",
      "starting batch  2  of  17 subject  10000  to  19999\n",
      "finising batch  2  of  17 number of records 563049\n",
      "starting batch  3  of  17 subject  20000  to  29999\n",
      "finising batch  3  of  17 number of records 842662\n",
      "starting batch  4  of  17 subject  30000  to  39999\n",
      "finising batch  4  of  17 number of records 1103157\n",
      "starting batch  5  of  17 subject  40000  to  49999\n",
      "finising batch  5  of  17 number of records 1347699\n",
      "starting batch  6  of  17 subject  50000  to  59999\n",
      "finising batch  6  of  17 number of records 1595090\n",
      "starting batch  7  of  17 subject  60000  to  69999\n",
      "finising batch  7  of  17 number of records 1831631\n",
      "starting batch  8  of  17 subject  70000  to  79999\n",
      "finising batch  8  of  17 number of records 2053692\n",
      "starting batch  9  of  17 subject  80000  to  89999\n",
      "finising batch  9  of  17 number of records 2263415\n",
      "starting batch  10  of  17 subject  90000  to  99999\n",
      "finising batch  10  of  17 number of records 2459774\n",
      "starting batch  11  of  17 subject  100000  to  109999\n",
      "finising batch  11  of  17 number of records 2634094\n",
      "starting batch  12  of  17 subject  110000  to  119999\n",
      "finising batch  12  of  17 number of records 2759071\n",
      "starting batch  13  of  17 subject  120000  to  129999\n",
      "finising batch  13  of  17 number of records 2898264\n",
      "starting batch  14  of  17 subject  130000  to  139999\n",
      "finising batch  14  of  17 number of records 3052655\n",
      "starting batch  15  of  17 subject  140000  to  149999\n",
      "finising batch  15  of  17 number of records 3197777\n",
      "starting batch  16  of  17 subject  150000  to  159999\n",
      "finising batch  16  of  17 number of records 3337194\n",
      "starting batch  17  of  17 subject  160000  to  169999\n",
      "finising batch  17  of  17 number of records 3418369\n"
     ]
    }
   ],
   "source": [
    "with open('../sql/feature_extraction/lab_person.sql', 'r') as f:\n",
    "    sql_q = f.read()\n",
    "    f.close()\n",
    "\n",
    "# Due to memory problem, we will query in batch\n",
    "# We will query 10000 at a time\n",
    "\n",
    "n_per_batch = 10000\n",
    "n_batches = len(pt_list) // n_per_batch + 1\n",
    "\n",
    "lab_df=None\n",
    "\n",
    "for i in range(n_batches):\n",
    "    print(\"starting batch \", i+1, \" of \", n_batches, \"subject \", i*n_per_batch, \" to \", (i+1)*n_per_batch - 1)\n",
    "    pt_sub = str(pt_list[i*n_per_batch:(i+1)*n_per_batch])[1:-1]\n",
    "    sql_q_sub = sql_q.replace('INSERT_PERSON_ID_LIST', pt_sub)\n",
    "\n",
    "    if lab_df is None:\n",
    "        print(\"no exisiting dataframe, creating new one\")\n",
    "        lab_df = pd.read_sql(sql_q_sub, conn)\n",
    "        print(\"finising batch \", i+1, \" of \", n_batches, 'number of records',len(lab_df))\n",
    "    else:\n",
    "        next_lab_df = pd.read_sql(sql_q_sub, conn)\n",
    "        \n",
    "        lab_df = pd.concat([lab_df, next_lab_df])\n",
    "        print(\"finising batch \", i+1, \" of \", n_batches, 'number of records',len(lab_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_df.to_csv('../data/lab/lab_person_22mar24.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_df = pd.read_csv('../data/lab/lab_person_22mar24.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comorbidities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting batch  1  of  17 subject  0  to  9999\n",
      "no exisiting dataframe, creating new one\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finising batch  1  of  17 number of records 10000\n",
      "starting batch  2  of  17 subject  10000  to  19999\n",
      "finising batch  2  of  17 number of records 20000\n",
      "starting batch  3  of  17 subject  20000  to  29999\n",
      "finising batch  3  of  17 number of records 30000\n",
      "starting batch  4  of  17 subject  30000  to  39999\n",
      "finising batch  4  of  17 number of records 40000\n",
      "starting batch  5  of  17 subject  40000  to  49999\n",
      "finising batch  5  of  17 number of records 50000\n",
      "starting batch  6  of  17 subject  50000  to  59999\n",
      "finising batch  6  of  17 number of records 60000\n",
      "starting batch  7  of  17 subject  60000  to  69999\n",
      "finising batch  7  of  17 number of records 70000\n",
      "starting batch  8  of  17 subject  70000  to  79999\n",
      "finising batch  8  of  17 number of records 80000\n",
      "starting batch  9  of  17 subject  80000  to  89999\n",
      "finising batch  9  of  17 number of records 90000\n",
      "starting batch  10  of  17 subject  90000  to  99999\n",
      "finising batch  10  of  17 number of records 100000\n",
      "starting batch  11  of  17 subject  100000  to  109999\n",
      "finising batch  11  of  17 number of records 110000\n",
      "starting batch  12  of  17 subject  110000  to  119999\n",
      "finising batch  12  of  17 number of records 120000\n",
      "starting batch  13  of  17 subject  120000  to  129999\n"
     ]
    }
   ],
   "source": [
    "with open('../sql/feature_extraction/comorb.sql', 'r') as f:\n",
    "    sql_q = f.read()\n",
    "    f.close()\n",
    "\n",
    "# Due to memory problem, we will query in batch\n",
    "# We will query 10000 at a time\n",
    "\n",
    "n_per_batch = 10000\n",
    "n_batches = len(pt_list) // n_per_batch + 1\n",
    "\n",
    "comorb_df=None\n",
    "\n",
    "for i in range(n_batches):\n",
    "    print(\"starting batch \", i+1, \" of \", n_batches, \"subject \", i*n_per_batch, \" to \", (i+1)*n_per_batch - 1)\n",
    "    pt_sub = str(pt_list[i*n_per_batch:(i+1)*n_per_batch])[1:-1]\n",
    "    sql_q_sub = sql_q.replace('INSERT_PERSON_ID_LIST', pt_sub)\n",
    "\n",
    "    if comorb_df is None:\n",
    "        print(\"no exisiting dataframe, creating new one\")\n",
    "        comorb_df = pd.read_sql(sql_q_sub, conn)\n",
    "        print(\"finising batch \", i+1, \" of \", n_batches, 'number of records',len(comorb_df))\n",
    "    else:\n",
    "        next_comorb_df = pd.read_sql(sql_q_sub, conn)\n",
    "        \n",
    "        comorb_df = pd.concat([comorb_df, next_comorb_df])\n",
    "        print(\"finising batch \", i+1, \" of \", n_batches, 'number of records',len(comorb_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comorb_df.to_pickle('../data\\comorb\\comorb_person_22mar24.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "comorb_df = pd .read_pickle('../data\\comorb\\comorb_person_22mar24.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
